{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02325b01",
   "metadata": {},
   "source": [
    "# Random Forest\n",
    "### Modelo de clasificación\n",
    "\n",
    "Un modelo Random Forest está formado por un conjunto (ensemble) de árboles de decisión individuales, cada uno entrenado con una muestra aleatoria extraída de los datos de entrenamiento originales mediante bootstrapping). Esto implica que cada árbol se entrena con unos datos ligeramente distintos. En cada árbol individual, las observaciones se van distribuyendo por bifurcaciones (nodos) generando la estructura del árbol hasta alcanzar un nodo terminal. La predicción de una nueva observación se obtiene agregando las predicciones de todos los árboles individuales que forman el modelo.\n",
    "\n",
    "[Fuente](https://www.cienciadedatos.net/documentos/py08_random_forest_python.html)\n",
    "\n",
    "### Aplicación:\n",
    "\n",
    "En este ejercicio aplicamos este modelo de aprendizaje automático con dos categorías de partículas subatomicas y cuatro de sus principales características. La meta es entrenar el algoritmo para ser capaz de separar estas categorías conociendo únicamente sus características."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160d29e4",
   "metadata": {},
   "source": [
    "# 1. Importamos las librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7caed8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "21/12/02 22:49:17 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(\"RandomForestClassifierExample\")\\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae23faaf",
   "metadata": {},
   "source": [
    "# 2. Cargamos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7950deea",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.format(\"csv\").load(\"data.csv\", header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c896a30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "data = data.drop(\"_c0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66367af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------+-------------+--------+-------------+\n",
      "|Label|       TrackP|      TrackPt|MuonFlag|         SpdE|\n",
      "+-----+-------------+-------------+--------+-------------+\n",
      "|Other|74791.1562629|3141.93067698|     1.0|3.20000004768|\n",
      "|Ghost|2738.48998933|199.573653278|     0.0|3.20000004768|\n",
      "|Ghost|2161.40990765|94.8294175338|     0.0|          0.0|\n",
      "|Other|15277.7304903|808.631063989|     0.0|3.20000004768|\n",
      "|Other|7563.70019502|1422.56921358|     0.0|3.20000004768|\n",
      "|Other|62641.6210901|3195.36230097|     0.0|3.20000004768|\n",
      "|Other|18872.8105703|1428.89675193|     0.0|3.20000004768|\n",
      "|Ghost|1993.55004844|469.429473483|     0.0|          0.0|\n",
      "|Other|90635.2968712|4560.59667592|     0.0|3.20000004768|\n",
      "|Other|11633.6699412|286.894581101|     0.0|          0.0|\n",
      "|Other|3432.92993402|447.756746761|     0.0|          0.0|\n",
      "|Other|21985.5390787|1616.39540194|     0.0|3.20000004768|\n",
      "|Other|  5666.160153|334.631435959|     0.0|          0.0|\n",
      "|Other|72726.6015693|3350.76196972|     1.0|3.20000004768|\n",
      "|Other|31465.6992176|839.893370406|     0.0|3.20000004768|\n",
      "|Other|100204.546879|4152.17822691|     1.0|3.20000004768|\n",
      "|Other|5402.31982176|925.537839341|     0.0|3.20000004768|\n",
      "|Other|4081.04003133|99.0788725761|     0.0|3.20000004768|\n",
      "|Other|9824.12988681|309.734592625|     0.0|3.20000004768|\n",
      "|Other|3559.33004986|1055.70443951|     0.0|3.20000004768|\n",
      "+-----+-------------+-------------+--------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10205f9e",
   "metadata": {},
   "source": [
    "# 3. Procesamiento de datos\n",
    "\n",
    "- Cambiamos las variables numéricas al tipo correcto\n",
    "- Codificamos las etiquetas\n",
    "- Preparamos los vectores de características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb3d4834",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.sql.functions import col\n",
    "data = data.withColumn(\"TrackP\",data.TrackP.cast(DoubleType()))\n",
    "data = data.withColumn(\"TrackPt\",data.TrackPt.cast(DoubleType()))\n",
    "data = data.withColumn(\"MuonFlag\",data.MuonFlag.cast(DoubleType()))\n",
    "data = data.withColumn(\"SpdE\",data.SpdE.cast(DoubleType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "383e26e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "labelIndexer = StringIndexer(inputCol=\"Label\", outputCol=\"indexedLabel\").fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fa54bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=['TrackP', \"TrackPt\", \"MuonFlag\", 'SpdE'],\n",
    "    outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0c11d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------+-------------+--------+-------------+--------------------+\n",
      "|Label|       TrackP|      TrackPt|MuonFlag|         SpdE|            features|\n",
      "+-----+-------------+-------------+--------+-------------+--------------------+\n",
      "|Other|74791.1562629|3141.93067698|     1.0|3.20000004768|[74791.1562629,31...|\n",
      "|Ghost|2738.48998933|199.573653278|     0.0|3.20000004768|[2738.48998933,19...|\n",
      "|Ghost|2161.40990765|94.8294175338|     0.0|          0.0|[2161.40990765,94...|\n",
      "|Other|15277.7304903|808.631063989|     0.0|3.20000004768|[15277.7304903,80...|\n",
      "|Other|7563.70019502|1422.56921358|     0.0|3.20000004768|[7563.70019502,14...|\n",
      "|Other|62641.6210901|3195.36230097|     0.0|3.20000004768|[62641.6210901,31...|\n",
      "|Other|18872.8105703|1428.89675193|     0.0|3.20000004768|[18872.8105703,14...|\n",
      "|Ghost|1993.55004844|469.429473483|     0.0|          0.0|[1993.55004844,46...|\n",
      "|Other|90635.2968712|4560.59667592|     0.0|3.20000004768|[90635.2968712,45...|\n",
      "|Other|11633.6699412|286.894581101|     0.0|          0.0|[11633.6699412,28...|\n",
      "|Other|3432.92993402|447.756746761|     0.0|          0.0|[3432.92993402,44...|\n",
      "|Other|21985.5390787|1616.39540194|     0.0|3.20000004768|[21985.5390787,16...|\n",
      "|Other|  5666.160153|334.631435959|     0.0|          0.0|[5666.160153,334....|\n",
      "|Other|72726.6015693|3350.76196972|     1.0|3.20000004768|[72726.6015693,33...|\n",
      "|Other|31465.6992176|839.893370406|     0.0|3.20000004768|[31465.6992176,83...|\n",
      "|Other|100204.546879|4152.17822691|     1.0|3.20000004768|[100204.546879,41...|\n",
      "|Other|5402.31982176|925.537839341|     0.0|3.20000004768|[5402.31982176,92...|\n",
      "|Other|4081.04003133|99.0788725761|     0.0|3.20000004768|[4081.04003133,99...|\n",
      "|Other|9824.12988681|309.734592625|     0.0|3.20000004768|[9824.12988681,30...|\n",
      "|Other|3559.33004986|1055.70443951|     0.0|3.20000004768|[3559.33004986,10...|\n",
      "+-----+-------------+-------------+--------+-------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = assembler.transform(data)\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88a3caef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "featureIndexer = \\\n",
    "VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc36fe5",
   "metadata": {},
   "source": [
    "# 4. Separamos los datos en entrenamiento y prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72d8ca93",
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainingData, testData) = data.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6527d867",
   "metadata": {},
   "source": [
    "# 5. Definimos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "117c0a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\", numTrees=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b3ce6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\",\n",
    "                                   labels=labelIndexer.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af51312",
   "metadata": {},
   "source": [
    "# 6. Entrenamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1c46a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 345 ms, sys: 918 ms, total: 1.26 s\n",
      "Wall time: 8.69 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, rf, labelConverter])\n",
    "model = pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c7a8d4",
   "metadata": {},
   "source": [
    "# 7. Utilizamos el modelo para hacer predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28b2e4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+--------------------+\n",
      "|predictedLabel|label|            features|\n",
      "+--------------+-----+--------------------+\n",
      "|         Other|Ghost|[1209.81995125,39...|\n",
      "|         Other|Ghost|[1310.97998816,15...|\n",
      "|         Other|Ghost|[1333.31995905,39...|\n",
      "|         Ghost|Ghost|[1357.73999346,72...|\n",
      "|         Other|Ghost|[1391.38000701,25...|\n",
      "+--------------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 22:>                                                         (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "predictions = model.transform(testData)\n",
    "predictions.select(\"predictedLabel\", \"label\", \"features\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283b98e0",
   "metadata": {},
   "source": [
    "# 8. Evaluamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "99c92c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 23:===>                                                    (1 + 16) / 17]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0.15026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(\n",
    "labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71fb4a1",
   "metadata": {},
   "source": [
    "### El error que se obtiene al utilizar el modelo y los datos es de 0.15026"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ec7f0ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassificationModel: uid=RandomForestClassifier_8b6cc096e70a, numTrees=10, numClasses=2, numFeatures=4\n"
     ]
    }
   ],
   "source": [
    "rfModel = model.stages[2]\n",
    "print(rfModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61d1e228",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
